{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb5e4140-fdcf-4cab-93b7-5a3a51008fe1",
   "metadata": {},
   "source": [
    "## Set Up Environment - Pip Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a47dae12-5e37-4643-88d1-90d6bc4a9a51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install langchain llama-index pypdf faiss-cpu chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fbd01513-acab-4317-8a72-50bfaed8a9b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install sentence-transformers langchain-community langchain-huggingface langchain_ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a68f3880-f33b-4e12-9215-c445590a2001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99e55b3-d0f9-45c7-b877-1f92eacd27de",
   "metadata": {},
   "source": [
    "## Load the Resume (PDF) as Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "82118319-d900-43bf-b368-27ceb785a944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"pdfs/Vignesh_R_Resume.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac4db41-1e3a-48ca-b4de-7f7ec3b39031",
   "metadata": {},
   "source": [
    "## Chunk & Embed the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "975af48b-98bc-40d5-96d8-26aa1fdc7869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2976dbde-b904-48c5-b397-90957d5a84ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Chunk the content\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5255c8aa-9807-4f4e-893b-a76a39fa9632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-mpnet-base-v2\") #all-mpnet-base-v2, all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f8c2230f-8e20-4c41-9075-92418a704b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Store in FAISS vector store\n",
    "vectorstore = FAISS.from_documents(docs, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5142b28-24ee-4a41-8cfd-24668c5c7d9d",
   "metadata": {},
   "source": [
    "## Connect to Ollama Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e194c317-159d-4d8a-9cf4-d363686d0080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"gemma3:4b\", temperature=0.2, num_ctx=128000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff21f0c9-ea25-4e50-a81b-52e098468d38",
   "metadata": {},
   "source": [
    "## Build the RetrievalQA Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fc1c5339-6e91-4938-aa5b-1c569b55c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49459839-3838-47ca-b2c9-f51c6946f65e",
   "metadata": {},
   "source": [
    "## Ask Questions about the Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "28d5af5e-fd8a-4896-bcd2-9dfe51a7ca95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ✅ 1. What are my key skills and technologies mentioned in the resume?\n",
       "**Answer:**\n",
       "Here’s a breakdown of V Vignesh’s key skills and technologies as listed in the resume:\n",
       "\n",
       "**Programming Languages:** Python, SQL\n",
       "\n",
       "**Data Technologies & Methodologies:**\n",
       "*   Data Analytics\n",
       "*   Data Engineering\n",
       "*   Data Science\n",
       "*   Machine Learning\n",
       "*   Natural Language Processing (NLP)\n",
       "*   Computer Vision\n",
       "*   Large Language Models (LLM)\n",
       "*   NLTK\n",
       "*   Big Data\n",
       "*   Data Modeling\n",
       "*   Automation\n",
       "*   Medallion Architecture\n",
       "\n",
       "**Cloud Platforms:** AWS, Google Cloud Platform (GCP)\n",
       "\n",
       "**Data Tools & Platforms:**\n",
       "*   Airflow\n",
       "*   Apache Kafka\n",
       "*   Hadoop\n",
       "*   MySQL\n",
       "*   NumPy\n",
       "*   Pandas\n",
       "*   Postgres\n",
       "*   Tableau\n",
       "*   Looker\n",
       "*   Power BI\n",
       "*   Databricks\n",
       "*   Superset\n",
       "*   PySpark\n",
       "\n",
       "**Other Relevant Skills:** Git, Analytics, Customer Journey Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ✅ 2. What kind of projects have I worked on?\n",
       "**Answer:**\n",
       "Based on the provided context, Vinesh has worked on projects including:\n",
       "\n",
       "*   **Scalable ETL pipelines & Data models:** Architecting and constructing these for seamless data flow.\n",
       "*   **Sales Retrospective Analytics:** Measuring the effectiveness of sales and marketing campaigns.\n",
       "*   **Effort Score Calculation:** Developing a heuristic model to measure customer struggles during the customer journey.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ✅ 3. What job roles am I best suited for?\n",
       "**Answer:**\n",
       "Based on the provided context, V Vignesh is best suited for roles in Data Analytics, Data Engineering, and Data Science. Specifically, his experience with ETL pipelines, data modeling, Airflow, and various data technologies (SQL, Python, etc.) aligns well with these fields."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ✅ 4. Generate a short bio from my resume\n",
       "**Answer:**\n",
       "Here’s a short bio based on the provided resume:\n",
       "\n",
       "“Versatile Data Wizard with experience in Data Analytics, Engineering, and Science. As a Data Analytics Engineer at [Company Name - *not provided in the text*], I architected and constructed scalable ETL pipelines, utilized technologies like Python, SQL, and Airflow, and led a team to automate analytics processes, saving 500 hours of manual effort. I’m passionate about leveraging data to drive insights and solutions.”\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 204 ms, sys: 1.85 s, total: 2.05 s\n",
      "Wall time: 27.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "questions = [\n",
    "    \"1. What are my key skills and technologies mentioned in the resume?\",\n",
    "    \"2. What kind of projects have I worked on?\",\n",
    "    \"3. What job roles am I best suited for?\",\n",
    "    \"4. Generate a short bio from my resume\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    result = qa_chain.invoke(q)\n",
    "    display(Markdown(f\"### ✅ {q}\\n**Answer:**\\n{result['result']}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8f1d1f15-a3b7-457c-9fa0-86f745d8cdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ✅ Give me the candidate's Name, phone number and location in Key: value format such as Name:<name>\n",
       "Phone:<phone>\n",
       "Location:<location>\n",
       "\n",
       "**Answer:**\n",
       "\n",
       "```\n",
       "Name:Vignesh R\n",
       "Phone: +91 86085 77937\n",
       "Location: Bengaluru, Karnataka, India\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.7 ms, sys: 524 ms, total: 562 ms\n",
      "Wall time: 2.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "questions = [\n",
    "    \"Give me the candidate's Name, phone number and location in Key: value format such as Name:<name>\\nPhone:<phone>\\nLocation:<location>\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    result = qa_chain.invoke(q)\n",
    "    display(Markdown(f\"### ✅ {q}\\n\\n**Answer:**\\n\\n```\\n{result['result']}\\n```\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "db82d359-298a-4b30-885b-413ac6bcf03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ✅ Mention tools, technologies, languages, frameworks, libraries, environment only. For eg: \n",
       "Mention Jenkins instead of CI/CD tools, Mention AWS instead of Cloud, Mention YOLO instead of CV Libraries, Mention Figma instead of Wireframing tools, Mention Tableau instead of Visualisation tools, Mention Selenium instead of Testing tools\n",
       "\n",
       "**Answer:**\n",
       "\n",
       "```\n",
       "Here’s a list of tools, technologies, languages, frameworks, libraries, and environments based on the provided context:\n",
       "\n",
       "*   YOLO\n",
       "*   Tableau\n",
       "*   Python\n",
       "*   SQL\n",
       "*   Machine Learning\n",
       "*   Natural Language Processing (NLP)\n",
       "*   Computer Vision\n",
       "*   Large Language Models (LLM)\n",
       "*   NLTK\n",
       "*   Big Data\n",
       "*   Business Analytics\n",
       "*   AWS\n",
       "*   Google Cloud Platform (GCP)\n",
       "*   Airflow\n",
       "*   Apache Kafka\n",
       "*   Hadoop\n",
       "*   MySQL\n",
       "*   NumPy\n",
       "*   Pandas\n",
       "*   Postgres\n",
       "*   Tableau\n",
       "*   Looker\n",
       "*   Power BI\n",
       "*   Git\n",
       "*   Databricks\n",
       "*   PySpark\n",
       "*   Superset\n",
       "*   JIRA\n",
       "*   CI/CD tools (Implied by automation strategies)\n",
       "*   Cloud (Implied by AWS and GCP)\n",
       "*   JIRA\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 61.7 ms, sys: 510 ms, total: 572 ms\n",
      "Wall time: 7.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "questions = [\n",
    "    '''Mention tools, technologies, languages, frameworks, libraries, environment only. For eg: \n",
    "Mention Jenkins instead of CI/CD tools, Mention AWS instead of Cloud, Mention YOLO instead of CV Libraries, Mention Figma instead of Wireframing tools, Mention Tableau instead of Visualisation tools, Mention Selenium instead of Testing tools'''\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    result = qa_chain.invoke(q)\n",
    "    display(Markdown(f\"### ✅ {q}\\n\\n**Answer:**\\n\\n```\\n{result['result']}\\n```\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f90a5a8f-0994-4a1a-b505-5b58e9e767af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sources used:\n",
      " [Document(id='29eee783-b318-4cd2-aedd-6c150b416a0a', metadata={'producer': 'react-pdf', 'creator': 'react-pdf', 'creationdate': '2025-07-17T03:51:31+00:00', 'source': 'pdfs/Vignesh_R_Resume.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content=\"»  Managed ad-hoc Requests : Handled various data-pull requests from several teams inside the organisations, \\nto effectively contribute requesting team with Insights\\nEDUCATION\\n \\n Sri Shakthi Institute of Engineering Technology August 2015 - April 2019\\nBachelor's, Computer Engineering GPA: 7.3\\nCERTIFICATIONS\\n \\n AWS Certified Solutions Architect\\nJava Full Stack Certification\\nJapanese Language\"), Document(id='b1097bb0-e1ac-4092-9dab-fb9dfadbe91d', metadata={'producer': 'react-pdf', 'creator': 'react-pdf', 'creationdate': '2025-07-17T03:51:31+00:00', 'source': 'pdfs/Vignesh_R_Resume.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='LinkedIn Bengaluru, KA, India\\nData Analytics Engineer March 2022 - June 2023\\n»  Cheque validation using YOLO: Used imaging models to verify the validity and correctness of the Cheque \\nuploaded by Ad agencies\\n»  Driving Scale for Platform Intelligence : Crisp Automation of Manual Analytics. Results of this work can be \\nClient-ready Decks, Reports or PDF, Documents, generated within few clicks. (Saved 500 hours of Human \\nEfforts)'), Document(id='af5c4dad-8834-4177-8300-d6ee85549d4d', metadata={'producer': 'react-pdf', 'creator': 'react-pdf', 'creationdate': '2025-07-17T03:51:31+00:00', 'source': 'pdfs/Vignesh_R_Resume.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Data Analytics, Data Engineering & Data Science. \\nSKILLS\\n \\n Python, SQL, Machine Learning, Natural Language Processing (NLP), Computer Vision, Large Language \\nModels (LLM), NLTK, Big Data, Data Analytics, Business Analytics, AWS, Google Cloud Platform, Airflow, \\nApache Kafka, Hadoop, MySQL, NumPy, Pandas, Postgres, Tableau, Looker, Power BI, Data Analysis, JIRA, \\nGit, Analytics, Databricks, GCP, Cloud, PySpark, Superset, Data Engineering, Data Modeling, Automation, Data'), Document(id='345544ed-dbe9-4f42-a78e-8e4393920583', metadata={'producer': 'react-pdf', 'creator': 'react-pdf', 'creationdate': '2025-07-17T03:51:31+00:00', 'source': 'pdfs/Vignesh_R_Resume.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Efforts)\\n»  Scaled Sentiment Analytics, Marketing, Ad Analytics driving value of 1x to 100x, leveraging Advanced \\nautomation strategies for GTM\\n»  Tableau Dashboard Analytics : Built end-to-end Tableau Dashboards for visualising various business \\nverticals insights like Education, SAAS etc., for various Sales folks across the globe (Saved 200 hours of \\nHuman Efforts)')]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSources used:\\n\", result[\"source_documents\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747b0219-52e7-4b7c-ac06-42861f9613ca",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26b5de1-f605-40a8-aac0-4833ec9fabd7",
   "metadata": {},
   "source": [
    "## RAG with Qdrant + OpenAI + Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f09f254a-3096-465f-b4da-defcbcc1b708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.12/site-packages (0.3.26)\n",
      "Requirement already satisfied: qdrant-client in /opt/anaconda3/lib/python3.12/site-packages (1.15.0)\n",
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.12/site-packages (1.93.0)\n",
      "Requirement already satisfied: pypdf in /opt/anaconda3/lib/python3.12/site-packages (5.8.0)\n",
      "Requirement already satisfied: langchain-community in /opt/anaconda3/lib/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (0.3.70)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (0.4.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /opt/anaconda3/lib/python3.12/site-packages (from qdrant-client) (1.73.1)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.26 in /opt/anaconda3/lib/python3.12/site-packages (from qdrant-client) (1.26.4)\n",
      "Requirement already satisfied: portalocker<4.0,>=2.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from qdrant-client) (3.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from qdrant-client) (6.31.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /opt/anaconda3/lib/python3.12/site-packages (from qdrant-client) (1.26.20)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /opt/anaconda3/lib/python3.12/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /opt/anaconda3/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /opt/anaconda3/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain qdrant-client openai pypdf langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f05ff728-94d3-4b26-bfcf-5fff3b3d390b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: docker\n"
     ]
    }
   ],
   "source": [
    "!docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d8353a72-ab67-4f7c-8c99-479552b5b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3331bf11-10af-4b46-804e-ac5c19ff1dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Load and parse multiple PDF files ---\n",
    "pdf_dir = \"./pdfs\"\n",
    "all_docs = []\n",
    "\n",
    "for filename in os.listdir(pdf_dir):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(os.path.join(pdf_dir, filename))\n",
    "        all_docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2f7949f4-c2af-4b0d-ad01-88fac90b8dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Chunk the documents ---\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=150)\n",
    "chunks = text_splitter.split_documents(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d35a922b-c1dd-44ab-a0d2-556f2bdf18a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Embeddings using Hugging Face model ---\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "97930c3c-4243-4016-861c-2575e08ad5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: Load or create Qdrant Vector Store ---\n",
    "qdrant = Qdrant.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model,\n",
    "    location=\"http://localhost:6333\",\n",
    "    collection_name=\"python_docs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3bb7d6ed-7e2c-4e9c-9bbf-178cf2147fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 5: Load Ollama (Gemma 3b) ---\n",
    "llm = Ollama(model=\"gemma3:4b\", temperature=0.2, num_ctx=128000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a9246692-f239-4335-bef9-973b0bd14db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 6: Retrieval QA Chain ---\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=qdrant.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "35b38796-353f-40df-af23-b50775a52a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 7: Ask a question ---\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Sample list of questions\n",
    "questions = [\n",
    "    \"What is the difference between Python 2 and Python 3 mentioned in Core_Python_Programming?\",\n",
    "    \"Explain decorators with examples from Introduction_to_Python_Programming.\",\n",
    "    \"What scientific libraries are covered in Python_Scientific_Programming?\",\n",
    "    \"What are the key principles of designing scalable data systems according to Designing_Data_Intensive_Applications?\",\n",
    "    \"How is rate limiting explained in System_Design_Interview?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f1c59203-8981-424d-a4ad-061edac931b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 🧠 What is the difference between Python 2 and Python 3 mentioned in Core_Python_Programming?\n",
       "\n",
       "**Answer:**\n",
       "\n",
       "```\n",
       "According to the text, there are only two differences between Python 2 and Python 3.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Sources:\n",
      "- ./pdfs/Python_Scientific_Programming.pdf\n",
      "\n",
      "📄 Sources:\n",
      "- ./pdfs/Python_Scientific_Programming.pdf\n",
      "\n",
      "📄 Sources:\n",
      "- ./pdfs/Core_Python_Programming.pdf\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 🧠 Explain decorators with examples from Introduction_to_Python_Programming.\n",
       "\n",
       "**Answer:**\n",
       "\n",
       "```\n",
       "Based on the provided text, here’s an explanation of decorators, drawing from the context:\n",
       "\n",
       "Decorators in Python are “overlays” applied to function calls. They are additional calls that are executed when a function or method is declared. The syntax uses an “at-sign” ( @ ) followed by the decorator function name and any optional arguments.\n",
       "\n",
       "The text doesn't provide a concrete example of how decorators are used, but it explains the underlying concept and syntax. It mentions that decorators were introduced in Python 2.4 and that older versions needed to be replaced with a specific assignment.\n",
       "\n",
       "I don't know how to provide a full example of decorators with code, as the provided text only describes the concept and syntax.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Sources:\n",
      "- ./pdfs/Core_Python_Programming.pdf\n",
      "\n",
      "📄 Sources:\n",
      "- ./pdfs/Core_Python_Programming.pdf\n",
      "\n",
      "📄 Sources:\n",
      "- ./pdfs/Core_Python_Programming.pdf\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 🧠 What scientific libraries are covered in Python_Scientific_Programming?\n",
       "\n",
       "**Answer:**\n",
       "\n",
       "```\n",
       "Based on the provided text, the scientific libraries covered in Python are NumPy, Pandas, Matplotlib, Seaborn, and scikit-learn.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Sources:\n",
      "- ./pdfs/Introduction_to_Python_Programming_-_WEB.pdf\n",
      "\n",
      "📄 Sources:\n",
      "- ./pdfs/Introduction_to_Python_Programming_-_WEB.pdf\n",
      "\n",
      "📄 Sources:\n",
      "- ./pdfs/Introduction_to_Python_Programming_-_WEB.pdf\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 🧠 What are the key principles of designing scalable data systems according to Designing_Data_Intensive_Applications?\n",
       "\n",
       "**Answer:**\n",
       "\n",
       "```\n",
       "According to Designing_Data_Intensive_Applications, the key principles of designing scalable data systems are:\n",
       "\n",
       "*   **Reliability:** Ensuring the system continues to operate correctly.\n",
       "*   **Scalability:** The ability to handle increasing amounts of data and user traffic.\n",
       "*   **Maintainability:** The ease with which the system can be modified and updated.\n",
       "\n",
       "The text also cautions against premature optimization, suggesting that you shouldn't build for scale if you don't need it, and emphasizes choosing the right tool for the job.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Sources:\n",
      "- ./pdfs/Designing_Data_Intensive_Applications.pdf\n",
      "\n",
      "📄 Sources:\n",
      "- ./pdfs/Designing_Data_Intensive_Applications.pdf\n",
      "\n",
      "📄 Sources:\n",
      "- ./pdfs/Designing_Data_Intensive_Applications.pdf\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 🧠 How is rate limiting explained in System_Design_Interview?\n",
       "\n",
       "**Answer:**\n",
       "\n",
       "```\n",
       "According to the provided text, rate limiting is explained as focusing on the server-side API rate limiter.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Sources:\n",
      "- ./pdfs/System_Design_Interview.pdf\n",
      "\n",
      "📄 Sources:\n",
      "- ./pdfs/System_Design_Interview.pdf\n",
      "\n",
      "📄 Sources:\n",
      "- ./pdfs/System_Design_Interview.pdf\n",
      "CPU times: user 165 ms, sys: 2.12 s, total: 2.28 s\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loop through each question and invoke your LLM (qa_chain or similar)\n",
    "for q in questions:\n",
    "    result = qa_chain.invoke(q)  # Replace with your actual LLM chain\n",
    "    answer = result['result'] if isinstance(result, dict) else result\n",
    "    display(Markdown(f\"### 🧠 {q}\\n\\n**Answer:**\\n\\n```\\n{answer}\\n```\"))\n",
    "    for doc in result[\"source_documents\"]:\n",
    "        print(\"\\n📄 Sources:\")\n",
    "        print(\"-\", doc.metadata.get(\"source\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7710ca52-9c2f-4e50-ab56-82c8bbf00c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
